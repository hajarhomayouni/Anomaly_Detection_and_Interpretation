This project introduces a novel anomaly detection and interpretation approach utilizing a transformer-based architecture that  reduces preprocessing needs by converting tabular data rows into a sentence-like structure and generates explanations for anomalies in the form of rule violations. Our approach consists of two main components: the Anomaly Detector and the Anomaly Interpreter. The Anomaly Detector utilizes a Transformer model with a customized embedding layer tailored for tabular data structures. 

While attention weights do not directly explain the model's reasoning, they can provide valuable insights when interpreted carefully. The Anomaly Interpreter uses attention weights to identify potential issues in anomalous data by comparing these weights with patterns in normal data. When the model labels a row as anomalous, the Interpreter examines closely related columns and compares their associations with those in the normal dataset using a benchmark association matrix. Deviations from typical associations are flagged as potential rule violations, highlighting unusual column pair relationships.

We evaluated our approach against conventional methods, such as Multi-Layer Perceptrons (MLPs) and Long Short-Term Memory (LSTM) networks, using labeled data from the Outlier Detection DataSets (ODDS). Our evaluation, which included standard metrics along with a novel mutation analysis technique, demonstrates that our method achieves accuracy comparable to existing techniques, while additionally providing interpretations of detected anomalies.
